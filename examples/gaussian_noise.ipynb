{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify the distributions are correct for Gaussian noise\n",
    "\n",
    "To verify that the median-marginalised distributions are correct, we simulate Gaussian noise with estimated PSDs and show that they follow the expected distributions.\n",
    "\n",
    "This will reproduce Figures 2-4 of [arXiv:2006.05292](https://arxiv.org/pdf/2006.05292.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "\n",
    "from scipy.signal.spectral import _median_bias\n",
    "from scipy.signal.windows import tukey\n",
    "from scipy.stats import binom, expon, f, norm, t\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "from median_marginalized.distributions import (\n",
    "    median_marginalised, median_marginalised_likelihood\n",
    ")\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams[\"font.family\"] = \"serif\"\n",
    "mpl.rcParams[\"font.serif\"] = \"Computer Modern Roman\"\n",
    "mpl.rcParams[\"font.size\"] = 20\n",
    "mpl.rcParams[\"text.usetex\"] = True\n",
    "mpl.rcParams[\"grid.alpha\"] = 0\n",
    "mpl.rcParams['text.latex.preamble'] = r'\\newcommand{\\mathdefault}[1][]{}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions to simulate data and estimate PSDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_backward_fft_with_window(data, tukey_alpha):\n",
    "    time_domain_data = np.fft.irfft(data, axis=-1)\n",
    "    window = tukey(time_domain_data.shape[-1], tukey_alpha)\n",
    "    return np.fft.rfft(time_domain_data * window, axis=-1)\n",
    "\n",
    "def generate_data_and_psds(n_average, n_samples, true_psd, tukey_alpha=0, do_ffts=True):\n",
    "    alpha = _median_bias(n_average)\n",
    "\n",
    "    real_data = np.array([np.random.normal(0, 1, n_samples) * true_psd ** 0.5 for _ in range(n_average + 1)])\n",
    "    imag_data = np.array([np.random.normal(0, 1, n_samples) * true_psd ** 0.5 for _ in range(n_average + 1)])\n",
    "    all_data = np.array([real + 1j * imag for real, imag in zip(real_data, imag_data)])\n",
    "    if not do_ffts and tukey_alpha > 0:\n",
    "        print(\"Not doing ffts although non-zero Tukey alpha passed.\")\n",
    "    if do_ffts:\n",
    "        all_data = forward_backward_fft_with_window(\n",
    "            data=all_data, tukey_alpha=tukey_alpha\n",
    "        )\n",
    "    mean_psd = np.mean(abs(all_data[1:]) ** 2 / 2, axis=0)\n",
    "    median_psd = np.median(abs(all_data[1:]) ** 2 / 2, axis=0) / alpha\n",
    "    return all_data, mean_psd, median_psd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the expected distribution of the Anderson-Darling statistic\n",
    "\n",
    "The expected distribution of the Anderson-Darling statistic does not have a known distribution.\n",
    "\n",
    "We therefore numerically estimate the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anderson_darling_sample(values, cdf):\n",
    "    \"\"\"Compute the Anderson-Darling statistics from a CDf and samples\"\"\"\n",
    "    return (\n",
    "        - len(values)\n",
    "        - np.sum(\n",
    "            (2 * np.arange(1, len(values) + 1) - 1)\n",
    "            * (np.log(cdf(values)) + np.log(1 - cdf(np.flipud(values))))\n",
    "        )\n",
    "        / len(values)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def generate_expected_anderson_darlings(n_realisations, n_samples, batch_size=32, tukey_alpha=0.1):\n",
    "    window_factor = 1 - 5 * tukey_alpha / 8\n",
    "    anderson_darlings = list()\n",
    "    for ii in tqdm(range(n_realisations // batch_size + 1)):\n",
    "        real_data = np.array([np.random.normal(0, 1, n_samples) for _ in range(batch_size)])\n",
    "        imag_data = np.array([np.random.normal(0, 1, n_samples) for _ in range(batch_size)])\n",
    "        all_data = np.array([real + 1j * imag for real, imag in zip(real_data, imag_data)])\n",
    "        all_data = forward_backward_fft_with_window(all_data, tukey_alpha) / window_factor ** 0.5\n",
    "        for data in all_data:\n",
    "            sorted_data = np.sort(np.concatenate([data.real, data.imag]))\n",
    "            anderson_darlings.append(\n",
    "                anderson_darling_sample(sorted_data, norm(loc=0, scale=1).cdf)\n",
    "            )\n",
    "    return anderson_darlings[:n_realisations]\n",
    "\n",
    "\n",
    "def generate_expected_anderson_darlings_power(n_realisations, n_samples, batch_size=32, tukey_alpha=0.1):\n",
    "    window_factor = 1 - 5 * tukey_alpha / 8\n",
    "    anderson_darlings = list()\n",
    "    for ii in tqdm(range(n_realisations // batch_size + 1)):\n",
    "        real_data = np.array([np.random.normal(0, 1, n_samples) for _ in range(batch_size)])\n",
    "        imag_data = np.array([np.random.normal(0, 1, n_samples) for _ in range(batch_size)])\n",
    "        all_data = np.array([real + 1j * imag for real, imag in zip(real_data, imag_data)])\n",
    "        all_data = forward_backward_fft_with_window(all_data, tukey_alpha) / window_factor ** 0.5\n",
    "        for data in all_data:\n",
    "            sorted_data = np.sort(np.abs(data.real + 1j * data.imag))\n",
    "            anderson_darlings.append(\n",
    "                anderson_darling_sample(sorted_data ** 2, expon(scale=2).cdf)\n",
    "            )\n",
    "    return anderson_darlings[:n_realisations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_anderson_darlings = generate_expected_anderson_darlings(n_realisations=16384 // 16, n_samples=16384)\n",
    "expected_anderson_darlings_power = generate_expected_anderson_darlings_power(n_realisations=16384 // 16, n_samples=16384)\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(np.sort(expected_anderson_darlings), np.linspace(1, 0, len(expected_anderson_darlings)))\n",
    "plt.plot(np.sort(expected_anderson_darlings_power), np.linspace(1, 0, len(expected_anderson_darlings_power)))\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"$A^{2}$\")\n",
    "plt.xlabel(\"$S(A^{2})$\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate the data\n",
    "\n",
    "We loop over a number of averages and segment durations, generate data and test the distribution matches the expected.\n",
    "\n",
    "First, we define a bunch of plotting functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_pp_confidence_levels(confidence_interval, confidence_interval_alpha, ax=None, n_samples=None):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    for ci, alpha in zip(confidence_interval, confidence_interval_alpha):\n",
    "        if n_samples is None:\n",
    "            n_samples = len(all_data[0])\n",
    "        _x_values = np.linspace(0, 1, 1000)\n",
    "        edge_of_bound = (1. - ci) / 2.\n",
    "        lower = binom.ppf(1 - edge_of_bound, n_samples, _x_values) / n_samples - _x_values\n",
    "        upper = binom.ppf(edge_of_bound, n_samples, _x_values) / n_samples - _x_values\n",
    "        lower[0] = 0\n",
    "        upper[0] = 0\n",
    "        ax.fill_between(_x_values, lower, upper, alpha=alpha, color='k')\n",
    "\n",
    "\n",
    "def plot_anderson_darlings(\n",
    "    exact_ads, mean_ads, median_ads, mean_bad_ads, median_bad_ads, expected_ads\n",
    "):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(\n",
    "        np.sort(exact_ads),\n",
    "        np.linspace(1, 0, len(exact_ads)),\n",
    "        color=\"C0\",\n",
    "        label=\"Exact\"\n",
    "    )\n",
    "    plt.plot(\n",
    "        np.sort(mean_ads),\n",
    "        np.linspace(1, 0, len(mean_ads)),\n",
    "        color=\"C1\",\n",
    "        label=\"Mean marginalised\"\n",
    "    )\n",
    "    plt.plot(\n",
    "        np.sort(median_ads),\n",
    "        np.linspace(1, 0, len(median_ads)),\n",
    "        color=\"C2\",\n",
    "        label=\"Median marginalised\"\n",
    "    )\n",
    "    plt.plot(\n",
    "        np.sort(mean_bad_ads),\n",
    "        np.linspace(1, 0, len(mean_bad_ads)),\n",
    "        color=\"C3\",\n",
    "        label=\"Mean unmarginalised\"\n",
    "    )\n",
    "    plt.plot(\n",
    "        np.sort(median_bad_ads),\n",
    "        np.linspace(1, 0, len(median_bad_ads)),\n",
    "        color=\"C4\",\n",
    "        label=\"Median unmarginalised\"\n",
    "    )\n",
    "    ads = np.sort([\n",
    "        expected_ads[ii * len(mean_ads): (ii + 1) * len(mean_ads)]\n",
    "        for ii in range(len(expected_ads) // len(mean_ads))\n",
    "    ], axis=-1)\n",
    "    for interval in [0.68, 0.95]:\n",
    "        plt.fill_betweenx(\n",
    "            np.linspace(1, 0, len(ads[0])),\n",
    "            np.quantile(ads, 0.5 - interval / 2, axis=0),\n",
    "            np.quantile(ads, 0.5 + interval / 2, axis=0),\n",
    "            color=\"k\",\n",
    "            alpha=0.1\n",
    "        )\n",
    "    ax = plt.gca()\n",
    "    ax.set_xlim(0, 5)\n",
    "    ax.set_xlabel(\"$A^2$\")\n",
    "    ax.set_ylabel(\"$S(A^2)$\")\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_whitened_data(exact_whitened_data, mean_whitened_data, median_whitened_data):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(np.linspace(-10, 10, 1000), norm(loc=0, scale=1).pdf(np.linspace(-10, 10, 1000)), color=\"C0\", label=\"Known\")\n",
    "    plt.plot(np.linspace(-10, 10, 1000), t(loc=0, scale=1, df=2 * n_average).pdf(np.linspace(-10, 10, 1000)), color=\"C1\", label=\"Mean\")\n",
    "    plt.plot(np.linspace(-10, 10, 1000), median_marginalised(loc=0, scale=1, n_average=n_average).pdf(np.linspace(-10, 10, 1000)), color=\"C2\", label=\"Median\")\n",
    "    \n",
    "    plt.hist(np.hstack([exact_whitened_data.real, exact_whitened_data.imag]), bins=200, histtype=\"step\", alpha=1, density=True, color=\"C0\")\n",
    "    plt.hist(np.hstack([mean_whitened_data.real, mean_whitened_data.imag]), bins=200, histtype=\"step\", alpha=1, density=True, color=\"C1\")\n",
    "    plt.hist(np.hstack([median_whitened_data.real, median_whitened_data.imag]), bins=200, histtype=\"step\", alpha=1, density=True, color=\"C2\")\n",
    "    ax = plt.gca()\n",
    "    ax.set_xlabel(\"$\\\\tilde{\\\\nu}$\")\n",
    "    ax.set_ylabel(\"$p(\\\\tilde{\\\\nu})$\")\n",
    "    ax.set_yscale(\"log\")\n",
    "    if n_average >= 31:\n",
    "        ax.set_xlim(-6, 6)\n",
    "    elif n_average >= 15:\n",
    "        ax.set_xlim(-8, 8)\n",
    "    else:\n",
    "        ax.set_xlim(-10, 10)\n",
    "    ax.set_ylim(1e-5, 1)\n",
    "    ax.legend(loc=\"lower center\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_whitened_power(exact_whitened_data, mean_whitened_data, median_whitened_data):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(np.linspace(0, 10, 1000) ** 2, expon(scale=2).pdf(np.linspace(0, 10, 1000) ** 2), color=\"C0\", label=\"Known\")\n",
    "    plt.plot(np.linspace(0, 10, 1000) ** 2, f(loc=0, scale=2, dfn=2, dfd=2 * n_average).pdf(np.linspace(0, 10, 1000) ** 2), color=\"C1\", label=\"Mean\")\n",
    "    plt.plot(np.linspace(0, 10, 1000) ** 2, median_marginalised_likelihood(loc=0, scale=1, n_average=n_average).pdf(np.linspace(0, 10, 1000) ** 2), color=\"C2\", label=\"Median\")\n",
    "    \n",
    "    plt.hist(abs(exact_whitened_data) ** 2, bins=200, histtype=\"step\", alpha=1, density=True, color=\"C0\")\n",
    "    plt.hist(abs(mean_whitened_data) ** 2, bins=200, histtype=\"step\", alpha=1, density=True, color=\"C1\")\n",
    "    plt.hist(abs(median_whitened_data) ** 2, bins=200, histtype=\"step\", alpha=1, density=True, color=\"C2\")\n",
    "    ax = plt.gca()\n",
    "    ax.set_xlabel(\"$|\\\\tilde{\\\\nu}|^2$\")\n",
    "    ax.set_ylabel(\"$\\\\mathcal{L}(\\\\tilde{\\\\nu})$\")\n",
    "    ax.set_yscale(\"log\")\n",
    "    if n_average >= 31:\n",
    "        ax.set_xlim(0, 30)\n",
    "    elif n_average >= 15:\n",
    "        ax.set_xlim(0, 40)\n",
    "    else:\n",
    "        ax.set_xlim(0, 70)\n",
    "    ax.set_ylim(1e-5, 1)\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_ppp_whitened(mean_data, median_data):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    ax = plt.gca()\n",
    "    _data = np.hstack([mean_data.real, mean_data.imag])\n",
    "    plot_pp_confidence_levels(confidence_interval, confidence_interval_alpha, ax, n_samples=len(_data) * 2)\n",
    "    plt.plot(\n",
    "        np.linspace(0, 1, len(_data)),\n",
    "        t(loc=0, scale=1, df=2 * n_average).cdf(np.sort(_data))\n",
    "        - np.linspace(0, 1, len(_data)),\n",
    "        color=\"C1\",\n",
    "        alpha=1,\n",
    "        label=\"Mean\"\n",
    "    )\n",
    "    _data = np.hstack([median_data.real, median_data.imag])\n",
    "    plt.plot(\n",
    "        np.linspace(0, 1, len(_data)),\n",
    "        median_marginalised(loc=0, scale=1, n_average=n_average).cdf(np.sort(_data))\n",
    "        - np.linspace(0, 1, len(_data)),\n",
    "        color=\"C2\",\n",
    "        alpha=1,\n",
    "        label=\"Median\"\n",
    "    )\n",
    "    _data = np.hstack([mean_data.real, mean_data.imag])\n",
    "    plt.plot(\n",
    "        np.linspace(0, 1, len(_data)),\n",
    "        norm(loc=0, scale=1).cdf(np.sort(_data))\n",
    "        - np.linspace(0, 1, len(_data)),\n",
    "        color=\"C3\",\n",
    "        alpha=1,\n",
    "        label=\"Mean unmarginalised\"\n",
    "    )\n",
    "    _data = np.hstack([median_data.real, median_data.imag])\n",
    "    plt.plot(\n",
    "        np.linspace(0, 1, len(_data)),\n",
    "        norm(loc=0, scale=1).cdf(np.sort(_data))\n",
    "        - np.linspace(0, 1, len(_data)),\n",
    "        color=\"C4\",\n",
    "        alpha=1,\n",
    "        label=\"Median unmarginalised\"\n",
    "    )\n",
    "        \n",
    "    ax.set_xlabel(\"$\\\\Phi(\\\\tilde{\\\\nu})$\")\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_yscale(\"linear\")\n",
    "    ax.ticklabel_format(axis=\"y\", style=\"plain\")\n",
    "    ax.set_ylabel(\"$\\\\Phi_{s}(\\\\tilde{\\\\nu}) - \\\\Phi(\\\\tilde{\\\\nu})$\")\n",
    "    plt.legend(loc=\"upper left\", ncol=2)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_ppp_power(mean_data, median_data):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    ax = plt.gca()\n",
    "    _data = abs(mean_data)\n",
    "    plot_pp_confidence_levels(confidence_interval, confidence_interval_alpha, ax, n_samples=len(_data))\n",
    "    plt.plot(\n",
    "        np.linspace(0, 1, len(_data)),\n",
    "        f(loc=0, scale=2, dfn=2, dfd=2 * n_average).cdf(np.sort(_data) ** 2)\n",
    "        - np.linspace(0, 1, len(_data)),\n",
    "        color=\"C1\",\n",
    "        label=\"Mean\"\n",
    "    )\n",
    "    _data = abs(median_data)\n",
    "    plt.plot(\n",
    "        np.linspace(0, 1, len(_data)),\n",
    "        median_marginalised_likelihood(loc=0, scale=1, n_average=n_average).cdf(np.sort(_data) ** 2)\n",
    "        - np.linspace(0, 1, len(_data)),\n",
    "        color=\"C2\",\n",
    "        label=\"Median\"\n",
    "    )\n",
    "    _data = abs(mean_data)\n",
    "    plt.plot(\n",
    "        np.linspace(0, 1, len(_data)),\n",
    "        expon(scale=2).cdf(np.sort(_data) ** 2)\n",
    "        - np.linspace(0, 1, len(_data)),\n",
    "        color=\"C3\",\n",
    "        alpha=1,\n",
    "        label=\"Mean unmarginalised\"\n",
    "    )\n",
    "    _data = abs(median_data)\n",
    "    plt.plot(\n",
    "        np.linspace(0, 1, len(_data)),\n",
    "        expon(scale=2).cdf(np.sort(_data) ** 2)\n",
    "        - np.linspace(0, 1, len(_data)),\n",
    "        color=\"C4\",\n",
    "        alpha=1,\n",
    "        label=\"Median unmarginalised\"\n",
    "    )\n",
    "        \n",
    "    ax.set_xlabel(\"$\\\\Phi(|\\\\tilde{\\\\nu}|)$\")\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_yscale(\"linear\")\n",
    "    ax.ticklabel_format(axis=\"y\", style=\"plain\")\n",
    "    ax.set_ylabel(\"$\\\\Phi_{s}(|\\\\tilde{\\\\nu}|) - \\\\Phi(|\\\\tilde{\\\\nu}|)$\")\n",
    "    plt.legend(loc=\"upper left\", ncol=2)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_frequency = 4096\n",
    "tukey_alpha = 0.1\n",
    "window_factor = 1 - 5 * tukey_alpha / 8\n",
    "\n",
    "legend_position = \"lower right\"\n",
    "confidence_interval = [0.68, 0.95, 0.997]\n",
    "confidence_interval_alpha = [0.1, 0.1, 0.1]\n",
    "hist_kwargs = dict(\n",
    "    histtype=\"step\", bins=100, density=True\n",
    ")\n",
    "\n",
    "total_samples = 1024\n",
    "\n",
    "for n_average, duration in zip([31, 63, 127], [8, 4, 4]):\n",
    "    n_samples = int(sampling_frequency * duration / 2 + 1)\n",
    "    true_psd = 10 ** np.linspace(-40, -45, n_samples)\n",
    "    true_psd[:duration * 10] = 0\n",
    "    true_psd[-1] = 0\n",
    "    mask = np.ones_like(true_psd, dtype=\"bool\")\n",
    "    mask[:duration * 20] = False\n",
    "    mask[-1] = False\n",
    "\n",
    "    exact_ads = [0]\n",
    "    mean_ads = [0]\n",
    "    median_ads = [0]\n",
    "    mean_bad_ads = [0]\n",
    "    median_bad_ads = [0]\n",
    "    exact_ads_power = [0]\n",
    "    mean_ads_power = [0]\n",
    "    median_ads_power = [0]\n",
    "    mean_bad_ads_power = [0]\n",
    "    median_bad_ads_power = [0]\n",
    "    all_exact_whitened_data = list()\n",
    "    all_mean_whitened_data = list()\n",
    "    all_median_whitened_data = list()\n",
    "\n",
    "    for _ in tqdm(range(total_samples // duration)):\n",
    "        all_data, mean_psd, median_psd = generate_data_and_psds(\n",
    "            n_average, n_samples, true_psd,\n",
    "            tukey_alpha=tukey_alpha, do_ffts=True\n",
    "        )\n",
    "        all_data = all_data[:, mask]\n",
    "        alpha = _median_bias(n_average)\n",
    "        analysis_data = all_data[-1]\n",
    "        mean_psd = np.mean(abs(all_data[:-1]) ** 2 / 2, axis=0)\n",
    "        median_psd = np.median(abs(all_data[:-1]) ** 2 / 2, axis=0) / alpha\n",
    "        \n",
    "        exact_whitened_data = np.sort(\n",
    "            analysis_data.real / true_psd[mask] ** 0.5 / window_factor ** 0.5\n",
    "        )\n",
    "        mean_whitened_data = np.sort(analysis_data.real / mean_psd ** 0.5)\n",
    "        median_whitened_data = np.sort(analysis_data.real / median_psd ** 0.5)\n",
    "        median_whitened_data = median_whitened_data[abs(median_whitened_data) < 20]\n",
    "\n",
    "        all_exact_whitened_data.append(analysis_data / true_psd[mask] ** 0.5 / window_factor ** 0.5)\n",
    "        all_mean_whitened_data.append(analysis_data / mean_psd ** 0.5)\n",
    "        all_median_whitened_data.append(analysis_data / median_psd ** 0.5)\n",
    "\n",
    "        exact_ads.append(anderson_darling_sample(\n",
    "            exact_whitened_data,\n",
    "            norm(loc=0, scale=1).cdf\n",
    "        ))\n",
    "        mean_ads.append(anderson_darling_sample(\n",
    "            mean_whitened_data,\n",
    "            t(loc=0, scale=1, df=2 * n_average).cdf\n",
    "        ))\n",
    "        median_ads.append(anderson_darling_sample(\n",
    "            median_whitened_data,\n",
    "            median_marginalised(loc=0, scale=1, n_average=n_average).cdf\n",
    "        ))\n",
    "        mean_bad_ads.append(anderson_darling_sample(\n",
    "            mean_whitened_data,\n",
    "            norm(loc=0, scale=1).cdf\n",
    "        ))\n",
    "        median_bad_ads.append(anderson_darling_sample(\n",
    "            median_whitened_data,\n",
    "            norm(loc=0, scale=1).cdf\n",
    "        ))\n",
    "\n",
    "        exact_ads_power.append(anderson_darling_sample(\n",
    "            np.sort(abs(analysis_data / true_psd[mask] ** 0.5 / window_factor ** 0.5)) ** 2,\n",
    "            expon(scale=2).cdf\n",
    "        ))\n",
    "        mean_ads_power.append(anderson_darling_sample(\n",
    "            np.sort(abs(analysis_data / mean_psd ** 0.5)) ** 2,\n",
    "            f(loc=0, scale=2, dfn=2, dfd=2 * n_average).cdf\n",
    "        ))\n",
    "        median_ads_power.append(anderson_darling_sample(\n",
    "            np.sort(abs(analysis_data / median_psd ** 0.5)) ** 2,\n",
    "            median_marginalised_likelihood(loc=0, scale=1, n_average=n_average).cdf\n",
    "        ))\n",
    "        mean_bad_ads_power.append(anderson_darling_sample(\n",
    "            np.sort(abs(analysis_data / mean_psd ** 0.5)) ** 2,\n",
    "            expon(scale=2).cdf\n",
    "        ))\n",
    "        median_bad_ads_power.append(anderson_darling_sample(\n",
    "            np.sort(abs(analysis_data / median_psd ** 0.5)) ** 2,\n",
    "            expon(scale=2).cdf\n",
    "        ))\n",
    "        \n",
    "    all_exact_whitened_data = np.concatenate(all_exact_whitened_data)\n",
    "    all_mean_whitened_data = np.concatenate(all_mean_whitened_data)\n",
    "    all_median_whitened_data = np.concatenate(all_median_whitened_data)\n",
    "\n",
    "    plot_whitened_data(\n",
    "        all_exact_whitened_data, all_mean_whitened_data, all_median_whitened_data\n",
    "    )\n",
    "    plot_whitened_power(\n",
    "        all_exact_whitened_data, all_mean_whitened_data, all_median_whitened_data\n",
    "    )\n",
    "    \n",
    "    plot_ppp_whitened(all_mean_whitened_data, all_median_whitened_data)\n",
    "    plot_ppp_power(all_mean_whitened_data, all_median_whitened_data)\n",
    "\n",
    "    plot_anderson_darlings(\n",
    "        exact_ads,\n",
    "        mean_ads,\n",
    "        median_ads,\n",
    "        mean_bad_ads,\n",
    "        median_bad_ads,\n",
    "        expected_anderson_darlings\n",
    "    )\n",
    "    plot_anderson_darlings(\n",
    "        exact_ads_power,\n",
    "        mean_ads_power,\n",
    "        median_ads_power,\n",
    "        mean_bad_ads_power,\n",
    "        median_bad_ads_power,\n",
    "        expected_anderson_darlings_power\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
